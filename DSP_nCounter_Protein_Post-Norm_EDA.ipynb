{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cad510-42d5-46d9-8796-c61e444eddca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ced866-990f-4edc-926b-614b5d4064df",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "A green text box indicates a code cell that must be run, without alteration, to complete the workflow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7d995-b16a-4627-95a5-877162e1062a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "An orange text box indicates an optional code cell that doesn't have to be run to complete the workflow, but can be run to complete optional tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7ad31-27e5-47b7-89e6-71416cb602c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "A blue text box indicates a code cell that requires user input - this cell also must be run to complete the workflow, but the user needs to modify the command in the cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4975c31-1891-47a9-a812-b287309b71cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "In addition, some text boxes contain particularly important information. These will be coloured red.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cff70b-d4e9-4ab9-b8dd-37984ad9a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4ffade8-4a03-4b63-9167-f777a74eaefc",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Import python functions </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    These packages should all be installed and available in your default environment. eResearch can help with installing modules and setting up environments. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "from scipy import stats as stats\n",
    "from copy import copy as copy\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.table import Table\n",
    "\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27332690-7fd2-4b8d-9e53-d80b718792e2",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Define/Import custom functions </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Custom functions for this workflow are imported from the functions folder. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a113e7-ed49-48a5-bc52-ee7338018606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.plotting import(\n",
    "    volcanoPlot, \n",
    "    plot_dendrogram,\n",
    "    get_factor_colours,\n",
    "    get_connectivity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da84d2c-6a55-4771-b97f-051eb33417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.eda import (get_AggloModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255decb-c8ab-42b3-8e23-240ba5d377ea",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\"> Configure output options for this run </span>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    The writeOutput variable below enables high level control for whether output files are written. This can be turned off to prevent overwriting existing files. <br>\n",
    "    AutoRunProject allows the selection of a folder location from a projects.txt config file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutput = False\n",
    "# writeOutput = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1676bd-ebb4-4b71-9a3d-56ef84d89861",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Read in config file </sapan>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    If running in autoRunProject mode, a project.txt file is used to hold all current projects, with one project per line. Inactive projects or comment lines start with a #. The project to run must be uncommented.<br>\n",
    "A config file (config.txt) or project file (project.txt) must be present in the folder given in the projects file or can be entered in the text below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4bf47-c513-4961-8915-b840ab7964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoRunProject = True\n",
    "autoRunProject = False\n",
    "\n",
    "if autoRunProject:\n",
    "    try:\n",
    "        with open('projects.txt', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if ((not line.startswith('#')) and (not line.strip()=='')):\n",
    "                    subfolder = line\n",
    "    except FileNotFoundError:\n",
    "        subfolder = input(\"Project file not found. Enter the name of the config folder and press enter (Must be same level as code folder)\")\n",
    "        # print('error')\n",
    "        \n",
    "else:\n",
    "    subfolder = input(\"Enter the name of the working folder (Must be same level as code folder)\")\n",
    "\n",
    "print(subfolder)\n",
    "\n",
    "os.chdir(\"../\" + subfolder)\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show current working directory to confirm that directory has been changed\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913af15-63b7-4ecb-bfb6-3d511ce84907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paths from config file\n",
    "configDict = {\n",
    "    'rootDir': '',\n",
    "    'initialDataPath' : '',\n",
    "    'QCDataPath' : '',\n",
    "    'labWorksheet01Path':'',\n",
    "    'sampleInfoFile' : '',\n",
    "    'projectName':'',\n",
    "    'selectedData': []\n",
    "}\n",
    "\n",
    "with open('./config.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if not line.startswith('#'):\n",
    "            line = line.strip()\n",
    "            fields = line.split(':')\n",
    "\n",
    "            if fields[0].strip()=='initialDataPath':\n",
    "                configDict[fields[0].strip()] = fields[1].strip().strip('\\'')\n",
    "            elif fields[0].strip()=='probeThresholdIdx':\n",
    "                configDict[fields[0].strip()] = int(fields[1].strip().strip('\\''))\n",
    "            elif fields[0].strip()=='selectedData':\n",
    "                tempList = fields[1].strip().strip('\\'').split(',')\n",
    "                tempList = [x.strip() for x in tempList]\n",
    "                configDict['selectedData'] = tempList\n",
    "            else:\n",
    "                configDict[fields[0].strip()] = fields[1].strip().strip('\\'')\n",
    "## ToDo: Add checks to ensure that minimal fields have been populated. Raise errors or warnings\n",
    "\n",
    "configDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3c94b-0812-4df2-bec7-894855e9c354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b7cd9e9-2dec-40fe-b777-fe5c59213909",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Run Analysis </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2cd9a-bfe9-4961-bccb-975ff8a17629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo:\n",
    "# add sample info file details into config file in previous notebook\n",
    "# sampleInfo_with_Wells.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff87a1-6e8d-4bf4-b09f-90d7268fbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Should initial filtering be done using none-mean-HKGeoMean normalised data. Using a type of background subtraction for filtering would bias towards removing noisy or low expressing samples. Removing these may give more accurate estimates of real probe values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047948f-3a4c-4ab4-91e9-89d7cb9a4031",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Read-in nanostring normalised data </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Read in normalised data from the final step of the QC notebook. This includes many versions of normalised data for comparison to help choose the final normalisation approach.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8e6e2-968e-4d2d-ae5c-33837cbcfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "normDir = os.path.join(configDict['rootDir'], 'Normalisation')\n",
    "# print(normDir)\n",
    "QCDataFile = [f for f in os.listdir(normDir) if (f.startswith('QC') and f.endswith('_preNorm.csv'))][0]\n",
    "print(QCDataFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc5ceb-600a-4429-9129-fbce79217a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(normDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b41968-1b35-4b37-9efc-0def51874aa6",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Sort samples and probes  </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Read and save the probe order and sample order from the pre normalisation data set for consistent organisation of data in plots.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc92ba-726f-4c20-adf6-4f03b5d13227",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF = pd.read_csv(os.path.join(normDir, QCDataFile), index_col=0)\n",
    "# QCDataDF.columns = [x.replace(' ','.') for x in QCDataDF.columns]\n",
    "# QCDataDF.columns = [x.replace('-','.') for x in QCDataDF.columns]\n",
    "\n",
    "codeClass = QCDataDF.loc[:,'Code.Class']\n",
    "\n",
    "probeOrder = QCDataDF.index[8:]\n",
    "sampleOrder = QCDataDF.columns[1:]\n",
    "\n",
    "# sampleOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84987a1-a0ee-436c-9a7c-c7aa894d7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4052103-51e3-4199-acbc-71db02aa976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QCDataDF.columns = [x.replace(' ','.') for x in QCDataDF.columns]\n",
    "# QCDataDF.columns = [x.replace('#','.') for x in QCDataDF.columns]\n",
    "# QCDataDF.columns = [x.replace('/','.') for x in QCDataDF.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc33dfe-2591-4bd2-94bf-659cb832e468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcafa6fb-a942-40d9-b81e-961db1771d62",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Read-in sampleInfo </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Read in sample information from sampleInfo_with_Wells.csv file created in the QC notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec76054-4052-40c7-ae2a-fd9a8e6bdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo = pd.read_csv(os.path.join(configDict['rootDir'], configDict['sampleInfoFile']), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd3a45-f39d-48e6-a0d6-f7905bb78599",
   "metadata": {},
   "outputs": [],
   "source": [
    "colTemp = sampleInfo.columns\n",
    "# colTemp = [x.replace(' ','.') for x in colTemp]\n",
    "# colTemp = [x.replace('-','.') for x in colTemp]\n",
    "sampleInfo.columns = colTemp\n",
    "\n",
    "\n",
    "sampleInfo = sampleInfo.loc[:,sampleOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7973c7-f93c-4c15-81b9-05d455a2a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfo.columns = [x.replace(' ','.') for x in sampleInfo.columns]\n",
    "# sampleInfo.columns = [x.replace('#','.') for x in sampleInfo.columns]\n",
    "# sampleInfo.columns = [x.replace('/','.') for x in sampleInfo.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced723f-ab09-48c8-95f5-e043f40b84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09a75d-2d33-4ee6-923b-5de5f3216645",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Read-in factors for use in data grouping from config file. </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Read in factors of interest as selected in QC notebook (reads from factor_lookup.tsv file).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2263590-3c25-4042-aed2-2f61000f9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors = input('enter factors to be used for groups to check probe expression. separate multiple factors by a comma')\n",
    "factors = configDict['selectedData']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a4cfb-fd32-4012-96e3-da2e747b4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dictionary to hold factors for group analysis\n",
    "factorDict = {}\n",
    "factorDict2 = {}\n",
    "\n",
    "for f in factors:\n",
    "    entries = list(set(sampleInfo.loc[f].values))\n",
    "    print(f)\n",
    "    print(entries)\n",
    "    # print(sorted(entries))\n",
    "    print()\n",
    "    factorDict[f] = entries\n",
    "    factorDict2[f] = {}\n",
    "    for e in entries:\n",
    "        factorDict2[f][e] = sampleInfo.columns[sampleInfo.loc[f] == e]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c3948-4d71-42db-a75c-2075b34ff593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3f408-d8f6-45bd-88fc-2d5eda009cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# factorDict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157863bf",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Visualise Nanostring Norm results and choose samples to be kept for final normalisation </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The first normalisation step is to view all normalisation options and select a relatively harsh/conservative method (e.g. with background subtraction) to run thresholding of probes and samples.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5626ade-d34f-4e2c-95b4-d417a8d507e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99611a-68a5-4b53-96af-924a4b2c344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QCDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537110be-bfb2-4cd9-a1bf-bf8e3328ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(normDir, 'NSNorm'))\n",
    "files = sorted(files)\n",
    "print(f'number of files found :\\t{len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08244ab1-60b1-4754-aa27-f32b87c49aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probeOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a253e3-1ead-49c4-9168-c5c1e38bae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleOrder = [x.replace(' ','.') for x in sampleOrder]\n",
    "# sampleOrder = [x.replace('#','.') for x in sampleOrder]\n",
    "# sampleOrder = [x.replace('/','.') for x in sampleOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a8f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 14\n",
    "height = 11\n",
    "\n",
    "fig, axs = plt.subplots(height, width, figsize=[40,25])\n",
    "# fig.suptitle('Nanostring Normalisation heatmaps')\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        fileIdx = x + y*width\n",
    "        tempDF = pd.read_csv(os.path.join(normDir, 'NSNorm',files[fileIdx]), index_col=0)\n",
    "#         axs[y][x].matshow(np.log2(tempDF + 1), aspect = 'auto', cmap='coolwarm')\n",
    "        axs[y][x].matshow(np.log2(tempDF.loc[probeOrder,sampleOrder] + 1), cmap='coolwarm')\n",
    "        axs[y][x].set_xticks([])\n",
    "        axs[y][x].set_yticks([])\n",
    "        axs[y][x].set_title(files[fileIdx][:-4])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('NSNorm.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830d984-6e0b-44e2-a564-cae5a6d2db28",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> What to look fo in the plots above </sapan>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Naming convention is extraERCC_BackgroundSubtraction_NormalisingFactor\n",
    "\n",
    "\n",
    "Plots are laid out in groups of 12, being 6 plots across and 2 plots down. Each set of 12 has the same normalising factor applies ( in order, these are ___,___,HKGeoMean,LowCVGeoMean,___).\n",
    "\n",
    "At this step we want to choose a method where low expressers (likely to be at or below the limit of detection) are set to a very low (or 0) value (dark blue). A safe choice is usually None_Mean_HKGeoMean (list index 27)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d2a4e-753c-4e59-a06e-1fb9958719b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "258147fe-2774-4613-9cc1-00ecdac9f6dc",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Threshold data </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Here we start to perform the final data thresholding before differential analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e0f1e-8ecc-444a-87de-0e14e59efd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define control probe names\n",
    "#ToDo: Make this robust for Mouse assays also.\n",
    "\n",
    "controlSet = set(['HYB-NEG', 'HYB-POS', 'Rb IgG', 'Ms IgG2a', 'Ms IgG1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f322d02-dc69-4133-8668-f9b85e4a6ec7",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Threshold probes and drop low or null expressing probes </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Description here\n",
    "\n",
    "The following variables can be set by the user, and the default values are as follows.\n",
    "\n",
    "threshold = 1.5\n",
    "expPropCutOff = 0.5\n",
    "SamplePropCutOff = 0.5\n",
    "\n",
    "Threshold is the probe value to define the limit of detection. With background subtraction, a relatively low value works well. A higher value will likely be needed if a normalised data set without background correction is used for this step.\n",
    "expPropCutOff: Expressed Proportion cutoff \n",
    "SamplePropCutOff: Sample Proportion Cutoff\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc53baa-0649-4d44-a229-bab07887828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Add in a variable called  thresholdData to hold data for comparison at thresholding stage. This will be read from one of the normalised files.\n",
    "\n",
    "# ToDo: Examine which normalised data should be used for thresholding. Does it make a difference if background correction has been performed?\n",
    "\n",
    "# ToDo: Read norm Method from config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71306fe6-f817-4978-94d6-c4fd747e9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholdData = pd.read_csv(os.path.join(normDir, 'NSNorm',files[51]), index_col=0) # none_mean_lowCVGeoMean\n",
    "# thresholdData = pd.read_csv(os.path.join(normDir, 'NSNorm',files[24]), index_col=0) #None_None_HKGeoMean\n",
    "\n",
    "thresholdData = pd.read_csv(os.path.join(normDir, 'NSNorm',files[27]), index_col=0) #None_Mean_HKGeoMean\n",
    "\n",
    "\n",
    "thresholdData.columns = [x.replace(' ','.') for x in thresholdData.columns]\n",
    "thresholdData.columns = [x.replace('-','.') for x in thresholdData.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981d6d9-1b03-4056-a627-ed6d3703ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Check that thresholding is not too restrictive. Should allow probes to be kept if they are expressed in more than half of any sub group.\n",
    "\n",
    "# ToDo: don't look for low expressing probes in groups with only 1 or 2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1b884-949e-4d45-8a5b-ff7b23ad35ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 1.5\n",
    "expPropCutOff = 0.5\n",
    "SamplePropCutOff = 0.5\n",
    "\n",
    "dropList = []\n",
    "dropSetTemp = []\n",
    "\n",
    "for f in factorDict2.keys():\n",
    "    print(f)\n",
    "    for g in factorDict2[f].keys():\n",
    "        # print(g)\n",
    "        # print(factorDict2[f][g])\n",
    "        groupLen = len(factorDict2[f][g])\n",
    "        # print(groupLen)\n",
    "        passThreshold = (thresholdData[factorDict2[f][g]]>threshold).sum(axis=1)\n",
    "        # print(passThreshold)\n",
    "        passThreshProp = (passThreshold/groupLen) < expPropCutOff\n",
    "        # print(passThreshProp)\n",
    "        failIdx = thresholdData.index[passThreshProp]\n",
    "        # print(failIdx)\n",
    "        # print(len(failIdx))\n",
    "\n",
    "        if (len(failIdx) > 0):\n",
    "            dropList.extend(list(failIdx))\n",
    "            dropSetTemp.append(list(failIdx))\n",
    "        # print(thresholdData.index[((thresholdData[factorDict2[f][g]]>2).sum(axis=1)/groupLen) < 0.5])\n",
    "\n",
    "dropList = list(set(dropList) - controlSet)\n",
    "print(dropList)\n",
    "print(dropSetTemp)\n",
    "\n",
    "# dropSet = set(tuple(x) for x in dropSetTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5374133-f369-40b9-89a5-1b2bfd298002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dropSet = set(dropSetTemp[0])\n",
    "    hasDrops = True\n",
    "except IndexError:\n",
    "    hasDrops = False\n",
    "\n",
    "if hasDrops:\n",
    "    for x in range(1,len(dropSetTemp)):\n",
    "        # print(x)\n",
    "        dropSet = dropSet & set(dropSetTemp[1])\n",
    "    \n",
    "    dropSet = dropSet - controlSet\n",
    "    # dropSet\n",
    "    dropList = list(dropSet)\n",
    "    # dropList\n",
    "    QCDataDF = QCDataDF.drop(index=dropList)\n",
    "    \n",
    "    \n",
    "    codeClass = codeClass[QCDataDF.index]\n",
    "    print(codeClass)\n",
    "    \n",
    "    \n",
    "    print(len(dropList))\n",
    "    print(dropList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb708be6-4e27-48d8-ae7b-929194bf72b8",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Threshold samples and drop low or null expressing samples </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Description here\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeec876-b374-4216-9c2a-ebf21c4bb9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropSamples = list(QCDataDF[QCDataDF.columns[1:]].T[(QCDataDF[QCDataDF.columns[1:]]>threshold).sum(axis=0)/len(QCDataDF.index) < SamplePropCutOff].index)\n",
    "print(f'dropSamples :\\t{dropSamples}')\n",
    "QCDataDF = QCDataDF.drop(labels=dropSamples, axis=1)\n",
    "\n",
    "QCDataDF.index.name = 'Name'\n",
    "QCDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c92da-0597-4dea-bc1f-110cbba71bc7",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Export data after dropping low expressing probes and samples </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Description here\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc6f31-0fbc-45da-8cce-35b695b31936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data after dropping probes and samples due to low expression\n",
    "\n",
    "project = configDict['projectName']\n",
    "\n",
    "qcDropCSV = 'QC_' + project + '_preNorm_Dropped.csv'\n",
    "\n",
    "writeOutput = True\n",
    "if writeOutput:\n",
    "    QCDataDF.to_csv(os.path.join(normDir, qcDropCSV))\n",
    "writeOutput= False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b59aad-444b-43c9-8b8c-561716123512",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> re-run NS norm with dropped data </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Description here\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bff30f-9ae9-4af0-aa37-2f1ced053a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# re-run NSNorm\n",
    "\n",
    "cmd = 'Rscript ../DSP_EDA_Protein/NSNorm.R -d ' + normDir + ' -s NSNormDropped -f ' + qcDropCSV\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e69b1-07cb-46a3-b58d-683ad38d9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3a51e-44e1-4eca-941b-43a5fbb6e316",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> View normalised-dropped data </sapan>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Description here\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4eb2d-6379-4f25-a3d7-051aea7a45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with viewing data and QC of normalised data\n",
    "\n",
    "files = os.listdir(os.path.join(normDir, 'NSNormDropped'))\n",
    "files = sorted(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee4c9d-f900-49ba-94fa-dc465eeb02fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 14\n",
    "\n",
    "fig, axs = plt.subplots(height, width, figsize=[40,25])\n",
    "fig.suptitle('Nanostring Normalisation heatmaps')\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        fileIdx = x + y*width\n",
    "        tempDF = pd.read_csv(os.path.join(normDir, 'NSNormDropped',files[fileIdx]), index_col=0)\n",
    "        axs[y][x].matshow(np.log2(tempDF + 1), cmap='coolwarm')\n",
    "        axs[y][x].set_xticks([])\n",
    "        axs[y][x].set_yticks([])\n",
    "        axs[y][x].set_title(files[fileIdx][:-4])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('NSNormDropped.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba7570-4506-4a27-ab10-1e2ccd76f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44556952-abf6-4636-900b-7bae0a8a3baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d317cf-87a3-4f22-844f-b9e932dfd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need function to drop samples from sample info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26740046-5f61-4ba4-b361-ed0c11a4079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c5a9fbe-05e0-4d34-a64f-7cf301fb90cf",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> generate groups for EdgeR analysis </sapan>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "In addition, some text boxes contain particularly important information. These will be coloured red.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb163cf-255c-4853-ab51-ad37f68106b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = noneMeanHKDF > 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noneMeanHKDF = pd.read_csv(os.path.join(normDir, 'NSNorm',files[27]), index_col=0)\n",
    "noneMeanHKDF = pd.read_csv(os.path.join(normDir, 'NSNormDropped',files[27]), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noneMeanHKDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupedExpressedIndex = noneMeanHKDF.loc[probeOrder].loc[((noneMeanHKDF > 0 ).sum(axis = 1) / len(noneMeanHKDF.columns) > 0.33333)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a768cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupedExpressedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390150d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(groupedExpressedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31255ab5-9a49-431e-83fa-b342d88533c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac7ba7-b419-45d9-97da-f1d843fbd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCData = pd.read_csv(os.path.join(normDir, QCDataFile), index_col=0)\n",
    "\n",
    "QCData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a30752",
   "metadata": {},
   "source": [
    "# Run EdgeR analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824bcb2-81a9-4343-9da8-1296d8795e9f",
   "metadata": {},
   "source": [
    "Write comparisons to a text file that will be parsed by the r script\n",
    "\n",
    "In form of factor.variable, factor.variable2, comparisonName\n",
    "1 comparison per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1536c2-134b-41a6-a02f-8a93b80504d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31a2673-b1c0-440a-a3b1-d19986a3c3b7",
   "metadata": {},
   "source": [
    "### extract potential factors for analysis from info file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021874d0-af03-4a0a-936d-72065e3ffe9c",
   "metadata": {},
   "source": [
    "### extract potential groups based on factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f30f6-8a8c-4fca-93d1-a7bd8400b96d",
   "metadata": {},
   "source": [
    "### Show group numbers for each of the comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc842f1-16a0-46fe-a006-5e78eb9c4b92",
   "metadata": {},
   "source": [
    "### Set up config file for EdgeR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2acb2f-d781-4ff3-99e0-a0a251c1e909",
   "metadata": {},
   "source": [
    "#### (Use helper notebook or uncomment code below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ba88c-c9b6-41b6-9504-93733b4bba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # groups = ['Broad_classification']\n",
    "# comps = [\n",
    "#     []\n",
    "# ]\n",
    "\n",
    "# compNames = []\n",
    "# for g in comps:\n",
    "#     ctemp = []\n",
    "#     for c in g:\n",
    "#         c = c.replace('.','_')\n",
    "#         c = c.replace(' - ','_vs_')\n",
    "#         ctemp.append(c)\n",
    "#     compNames.append(ctemp)\n",
    "\n",
    "# compNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65620684-b670-4037-a8f6-d444eeedaf7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outFile = 'EdgeR_Config.txt'\n",
    "\n",
    "# outLines = []\n",
    "# for g in range(len(groups)):\n",
    "#     groupLine = 'GROUP:' + groups[g]\n",
    "#     outLines.append(groupLine)\n",
    "    \n",
    "#     compLine = 'COMPARISON:'\n",
    "#     compNameLine = 'COMP_NAME:'\n",
    "#     for c in range(len(comps[g])):\n",
    "#         compLine += comps[g][c]\n",
    "#         compLine += ','\n",
    "#         compNameLine += compNames[g][c]\n",
    "#         compNameLine += ','\n",
    "    \n",
    "#     outLines.append(compLine)\n",
    "#     outLines.append(compNameLine)\n",
    "\n",
    "# with open(outFile, 'w') as o:\n",
    "#     o.write('\\n'.join(outLines))\n",
    "#     o.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078279a3-7f6e-4a86-8060-0d5ee160f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configDict['rootDir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ac1db-3744-40c9-9a0e-76c789e7dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d60a6-57e5-4973-8a2a-4189077360ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Ensure that EdgeR_config.txt has been populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7578a-5369-489b-96dc-8a52fdd95004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669cbfe-782f-4d7a-95ef-a256aedbf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose normalisation file for use with edgeR\n",
    "\n",
    "normPath = os.path.join('Normalisation','NSNormDropped')\n",
    "# normPath = os.path.join('Normalisation','NSNorm')\n",
    "print(normPath)\n",
    "\n",
    "# normFile = 'NanoStringNorm_52_none_mean_low.cv.geo.mean.csv'\n",
    "# normFile = 'NanoStringNorm_49_none_none_low.cv.geo.mean.csv'\n",
    "normFile = 'NanoStringNorm_25_none_none_housekeeping.geo.mean.csv'\n",
    "# normFile = 'NanoStringNorm_13_none_none_housekeeping.sum.csv'\n",
    "print(normFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e26f4-7644-46a9-aead-becfef5b8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample info file, export directory and \n",
    "\n",
    "sampleinfoFile = 'sampleInfo_with_wells.csv'\n",
    "\n",
    "runname = 'NS' + normFile[10:17]\n",
    "exportdir = os.path.join('EdgeR', runname)\n",
    "print(f'exportdir : {exportdir}')\n",
    "\n",
    "\n",
    "# ensure export directory is created\n",
    "\n",
    "try:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir))\n",
    "except FileNotFoundError:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir.split('/')[0]))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir))\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bda3f-ea49-4a00-93fe-c5b1e899a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to handle dropped samples that may still be present in sampleinfoFile. \n",
    "## Could be handled with another file, or by removing samples within R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ba967-0c9c-40bb-9012-af5be8369e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up command and run edgeR\n",
    "\n",
    "cmd = 'Rscript ../DSP_EDA_Protein/EdgeR.R -c ' + os.getcwd()\n",
    "cmd += ' -d ' + configDict['rootDir']\n",
    "cmd += ' -n ' + normPath\n",
    "cmd += ' -f ' + normFile\n",
    "cmd += ' -e ' + exportdir\n",
    "cmd += ' -i ' + sampleinfoFile\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fdfc8-d3eb-4274-83aa-b30a07b413b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75803582",
   "metadata": {},
   "source": [
    "# Convert MD Plots to Volcano Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files to run\n",
    "\n",
    "dataPath = os.path.join(configDict['rootDir'],exportdir,)\n",
    "filesMaster = []\n",
    "for root, folder, files in os.walk(dataPath):\n",
    "    files = [os.path.join(root, f) for f in files if (f.endswith('.csv') and f.startswith('MD_plot'))]\n",
    "    filesMaster.extend(files)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639af0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Run volcano plots\n",
    "\n",
    "# sigGenes = []\n",
    "for file in filesMaster:\n",
    "    if not (file[-7:-4] == '_tr'):\n",
    "        subGenes = volcanoPlot(dataPath, file, pVal=False)\n",
    "        # sigGenes.extend(subGenes)\n",
    "# sigGenes = list(set(sigGenes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40968b10-33ba-4ea0-a66c-62f79903e7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "610bb0c4-16f0-4e72-be5d-d2726f2396d6",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def3a6-a389-4404-99af-dc7828c4d6f6",
   "metadata": {},
   "source": [
    "### Plot heatmaps and dendrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8021a6-8ff3-46ee-9493-2a2c812e9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Ensure heatmaps are using relevant normalised data. Read data from NSNorm or EdgeR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1022dae-5232-429c-9f57-19a6e6860fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCData.drop(labels=['Code.Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b3a36-1062-4f1e-897a-13d86f859145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4aa60-e3b2-41d1-b7de-d16b8af35ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset dataframe to contain only significant probes and relevant AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da321f-cb5e-43de-add5-ff9d4747ac6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b763937-95eb-47b8-8ca6-bf13824ffbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073376bb-db7b-47ed-992e-feed691ee709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendroModel = AgglomerativeClustering(n_clusters=None, \n",
    "                                # affinity='euclidean', \n",
    "                                # metric='euclidean', \n",
    "                                metric='cosine', \n",
    "                                memory=None, \n",
    "                                connectivity=None, \n",
    "                                compute_full_tree=True, \n",
    "                                # linkage='ward', \n",
    "                                linkage='single', \n",
    "                                # linkage='complete', \n",
    "                                distance_threshold=0.1, \n",
    "                                compute_distances=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb21a1b-1768-4809-b4aa-b557324f0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo : Add linkage map from cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58f6be-ff92-4264-8d07-98ab3d20b659",
   "metadata": {},
   "source": [
    "### Read in  Factor lookup tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90215d4c-a0ec-42c6-aef8-63c57165727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_factor_lookup(file):\n",
    "    factorLookup = {}\n",
    "    varLookup = {}\n",
    "    vars = []\n",
    "    \n",
    "    sep = '\\t'\n",
    "    if file.lower().endswith('.tsv'):\n",
    "        sep= '\\t'\n",
    "    elif file.lower().endswith('.csv'):\n",
    "        sep= ','\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            factorVariable = line.split(':')\n",
    "\n",
    "            # ToDo: CHeck this is correct patter for assertions\n",
    "            assert len(factorVariable)==2, 'Factor lookup file is incomplete or incorrectly formatted'\n",
    "            # print(factorVariable)\n",
    "            factor = factorVariable[0]\n",
    "            factor = factor.strip()\n",
    "            # print(factor)\n",
    "            variables = factorVariable[1].split(sep)\n",
    "            # print(variables)\n",
    "            variables = [x.strip() for x in variables]\n",
    "            vars.extend(variables)\n",
    "            for var in variables:\n",
    "                factorLookup[var] = factor\n",
    "\n",
    "    return(factorLookup, varLookup, vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af5518-07e9-4b1e-a274-5bbfcd75e707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e64b74-9025-48c5-9755-bef48c28f19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54678fc5-f8a4-4b89-b3f7-b1fecd616f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_AOIs(fileName, factorLookup):\n",
    "    # Extract subpopulation attributes from file name\n",
    "    fields = fileName[:-4].split('_')\n",
    "    fields.remove('MD')\n",
    "    fields.remove('plot')\n",
    "    vsIDX = fields.index('vs')\n",
    "    numIDXs = [x for x in range(vsIDX)]\n",
    "    denomIDXs = [x for x in range(vsIDX+1,len(fields))]\n",
    "    AOISuperSets = [[],[]]\n",
    "    \n",
    "    for i, IDXs in enumerate([numIDXs,denomIDXs]):\n",
    "        for idx in IDXs:\n",
    "            factor = fields[idx]\n",
    "            print('factor')\n",
    "            print(factor)\n",
    "            factorType = factorLookup[factor]\n",
    "            thisSet = set(sampleInfo.loc[:,sampleInfo.loc[factorType] == factor].columns)\n",
    "            AOISuperSets[i].append(thisSet)\n",
    "    numeratorAOIs = set.intersection(*AOISuperSets[0])\n",
    "    denominatorAOIs = set.intersection(*AOISuperSets[1])     \n",
    "    relevantAOIs = list(numeratorAOIs | denominatorAOIs)\n",
    "    relevantAOIs = [x.replace('.',' ') for x in relevantAOIs]\n",
    "    fields.remove('vs')\n",
    "    return(relevantAOIs, fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796ac4f-53c5-4968-8736-2cebf3cc3920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312ae23-39df-4292-b57d-469edc7f573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "factorLookup, varLookup, vars = read_factor_lookup('factor_lookup.tsv')\n",
    "factors = list(set(factorLookup.values()))\n",
    "varLookup = dict(zip(vars, np.arange(0.1,0.9,0.8/len(vars))))\n",
    "\n",
    "\n",
    "for file in filesMaster:   # Iterate through files\n",
    "\n",
    "\n",
    "    if not (file[-7:-4] == '_tr'):  # Ignore _tr files with more stringent expression thresholding\n",
    "        print(file)\n",
    "        fileName = file.split('/')[-1]\n",
    "        relevantAOIs, fileNameFields = get_relevant_AOIs(fileName, factorLookup)\n",
    "\n",
    "\n",
    "        ## Move function to get factor lookup et here so that only relevant factors are used for each plot to simplify plots and colouring.\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        subGenes = volcanoPlot(dataPath, file, pVal=True, plot=False)\n",
    "        if (len(subGenes) <= 1):\n",
    "            print('No subgenes were found, continuing with next comparison\\n\\n')\n",
    "            continue\n",
    "        tempDF = pd.read_csv(file)\n",
    "        tempDF.columns = [x.replace('.',' ') for x in tempDF.columns]\n",
    "        # heatMapData = QCData.loc[subGenes,relevantAOIs] # Use EdgeR Input data for heatmaps\n",
    "        heatMapData = tempDF.loc[subGenes,relevantAOIs] # Use EdgeR model output data for heatmaps\n",
    "\n",
    "        print(heatMapData.shape)\n",
    "        # print(heatMapData)\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(len(relevantAOIs)*0.27+3.5, len(subGenes)*0.27+3),width_ratios=[4,len(relevantAOIs),1], height_ratios=[4,2,len(subGenes)])\n",
    "        ## Generate sample dendrogram\n",
    "\n",
    "        if ((heatMapData.shape[1])>2):\n",
    "            # dendroModel = get_AggloModel('EuclideanWard_T', heatMapData)\n",
    "            # dendroModel = get_AggloModel('CosineWard_T', heatMapData)\n",
    "\n",
    "\n",
    "            dendroModel = AgglomerativeClustering(n_clusters=None, \n",
    "                                    # metric='euclidean', \n",
    "                                    metric='cosine', \n",
    "                                    memory=None, \n",
    "                                    connectivity=kneighbors_graph(heatMapData.T,2), \n",
    "                                    # connectivity=sklearn.neighbors.kneighbors_graph(heatMapData.T,2), \n",
    "                                    # connectivity=sklearn.neighbors.kneighbors_graph(1 - sklearn.metrics.pairwise.cosine_distances(heatMapData.T),2), \n",
    "                                    compute_full_tree=True, \n",
    "                                    linkage='complete', \n",
    "                                    distance_threshold=0.1, \n",
    "                                    compute_distances=True\n",
    "                                   )\n",
    "\n",
    "        else:\n",
    "            dendroModel = get_AggloModel('EuclideanWard_None', heatMapData)\n",
    "\n",
    "        model = dendroModel.fit(heatMapData.T)\n",
    "        labels = plot_dendrogram(model, \n",
    "                                 truncate_mode=None, \n",
    "                                 p=5, \n",
    "                                 ax=axes[0][1])\n",
    "        AOINamesDendro = [heatMapData.columns[int(x)] for x in labels]\n",
    "\n",
    "        \n",
    "        ## Generate probe dendrogram\n",
    "        if ((heatMapData.shape[0])>2):\n",
    "            dendroModel = get_AggloModel('EuclideanWard', heatMapData)\n",
    "        else:\n",
    "            dendroModel = get_AggloModel('EuclideanWard_None', heatMapData)\n",
    "\n",
    "        model = dendroModel.fit(heatMapData)\n",
    "        labels = plot_dendrogram(model, \n",
    "                                 truncate_mode=None, \n",
    "                                 p=5, \n",
    "                                 orientation = 'left',\n",
    "                                 ax=axes[2][0])\n",
    "        probeNamesDendro = [heatMapData.index[int(x)] for x in labels][::-1]\n",
    "\n",
    "        axes[0][0].axis('off')\n",
    "        axes[1][0].axis('off')\n",
    "        axes[0][2].axis('off')\n",
    "        axes[1][2].axis('off')\n",
    "        \n",
    "        axes[0][1].tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False) \n",
    "        axes[1][1].tick_params(left = False, right = True, labelright = True, labelbottom = False, top = False, bottom = False) \n",
    "        axes[2][0].tick_params(left = False, right = False, labelleft = False, labelright = False, labelbottom = False, bottom = False) \n",
    "\n",
    "        # factors=['Histo_Stage','Segment_Name']\n",
    "        # varLookup={'IA':0.1,'IIA':0.2,'IIB':0.33,'IV':0.4,'Segment1':0.65,'Segment2':0.85}\n",
    "        # factors=['Obese','arthritis']\n",
    "        # varLookup={'NonObese':0.1,'Obese':0.2,'Epi':0.33, 'Sub':0.4, 'Full':0.5, 'NOA':0.65,'OA':0.85}\n",
    "        # factors=['Broad_classification','Tissue','Cyst_Size']\n",
    "        # varLookup={'Primary':0.15,'Secondary':0.85, 'purple':0.2, 'green':0.33 , 'mixed':0.4, 'large':0.5, 'small':0.65, 'na':0.95}\n",
    "        axes[1][1].matshow(get_factor_colours(AOINamesDendro, factors, varLookup, sampleInfo), \n",
    "                           cmap = 'gist_rainbow', \n",
    "                           aspect='auto', \n",
    "                           vmin=0, \n",
    "                           vmax=1)\n",
    "        axes[1][1].yaxis.tick_right()\n",
    "        axes[1][1].set_yticks(np.linspace(0, len(factors)-1, len(factors)), factors)\n",
    "        axes[1][1].set_xticks([])\n",
    "\n",
    "        axes[0][2].matshow([[varLookup[x]] for x in fileNameFields], \n",
    "                           cmap = 'gist_rainbow', \n",
    "                           aspect='auto', \n",
    "                           vmin=0, \n",
    "                           vmax=1)\n",
    "        \n",
    "        axes[2][1].matshow(np.log2(heatMapData.loc[probeNamesDendro,AOINamesDendro]), cmap = 'coolwarm', aspect='auto')\n",
    "        axes[2][1].xaxis.tick_bottom()\n",
    "        axes[2][1].yaxis.tick_right()\n",
    "        # axes[2][1].set_xticklabels(AOINamesDendro)\n",
    "        # axes[2][1].set_xticks(np.linspace(0, len(AOINamesDendro)-1, len(AOINamesDendro)), ['AOI_' + x[22:-9] for x in AOINamesDendro], rotation = 45, ha='right')\n",
    "        axes[2][1].set_xticks(np.linspace(0, len(AOINamesDendro)-1, len(AOINamesDendro)), ['AOI_' + x[22:] for x in AOINamesDendro], rotation = 45, ha='right')\n",
    "        axes[2][1].set_yticks(np.linspace(0, len(probeNamesDendro)-1, len(probeNamesDendro)), probeNamesDendro)\n",
    "\n",
    "        norm = Normalize(vmin=np.log2(heatMapData.values.max()), vmax=np.log2(heatMapData.values.max()), clip=False)\n",
    "        fig.colorbar(ScalarMappable(norm=norm, cmap='coolwarm'), cax=axes[2][2])\n",
    "        \n",
    "        fig.suptitle(fileName[:-4])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file[:-4] + '_Heatmap.svg')\n",
    "        plt.show()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556971b-5056-461c-aea0-95f3f5b7a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = list(set(factorLookup.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008d3f0-1fa8-4028-9c67-d0d3a4d2b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.1,0.9,0.8/len(factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57ab57-c6f8-48a8-82f4-af6302f729fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80494c21-d4d8-4671-803a-afa9d1075d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8a3f9-f512-4b88-b711-79b7e300d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "varLookup = zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2228158-de95-47c1-a4b0-a096b487adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(factors, np.arange(0.1,0.9,0.8/len(factors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d2e2a-874b-4a70-afe4-f522374c5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo : Add x ticks to sample plot\n",
    "# ToDo : Add legend for sample ID plot\n",
    "# ToDo : Add legend for heatmap\n",
    "# ToDo : automate extraction of factor names and variables\n",
    "\n",
    "# ToDo : Use a lookup dictionary to abbreviate/shorten probe names. OR, work out a better spacing method to accommodate long probe names without creating so much white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95fd2c-ae7a-495e-b3b5-0e92109b3824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b9c47-2a55-4111-8e19-fafff92cc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed17d0e-38d6-453d-b518-d622521705a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e545f6f-d245-450d-8d5b-06d4b0fc793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30fb95-7978-4465-bd34-a4fe1e7c94de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07303148-d96d-46c4-a151-24baf97f2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682f856-0a35-4a8a-be5f-73321d82c134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5d638-7858-4b31-a941-4a7df101492c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f5f81a-a926-4b46-b166-10477c8c1b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83743fa0-d398-45a4-b87e-895fd07515bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.kneighbors_graph(heatMapData,2)\n",
    "# knn = sklearn.neighbors.kneighbors_graph(heatMapData.T,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082257c-b223-46d7-9c81-d9d354733845",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7772117-09e3-4e08-a7e3-7b5f42e1b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(knn.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f364af-3e5f-497e-af06-846b56583415",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c72ed9-5f5a-483f-965b-7e48f9433e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ddc96-bbed-4cca-8401-c4bfb9c13a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = 1 - sklearn.metrics.pairwise.cosine_distances(heatMapData)\n",
    "\n",
    "# result = 1 - spatial.distance.cosine(heatMapData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dbc54-87f3-42c3-9668-6e27ad2e8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fc24e-9c66-4720-a2a5-6ddc5aea5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15011a-2f33-4583-b604-0d5808e90741",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnCosine = sklearn.neighbors.kneighbors_graph(result,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc554c-0415-4f97-abbe-fb5de66676eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnCosine.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acbdb2-a357-4d1c-ad3d-dfcb8338aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(knnCosine.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ee010-7e0e-468f-9f42-73d60188d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021c83a-d3d7-4271-a3c1-73938f32214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nonZero_mean(tempData, cols):\n",
    "    tempData = tempData.loc[:,cols]\n",
    "    seriesList=[]\n",
    "    for factor in tempData.index:\n",
    "        theseVals = tempData.loc[factor,:]\n",
    "        byDict = sampleInfoTemp.loc['TMA_Core',cols].to_dict()    \n",
    "        nonZeroDict = {}\n",
    "        for k,v in byDict.items():\n",
    "            thisVal = theseVals[k]\n",
    "            if thisVal == 0:\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    nonZeroDict[v].append(thisVal)\n",
    "                except KeyError:\n",
    "                    nonZeroDict[v] = [thisVal]\n",
    "        for k,v in byDict.items():\n",
    "            if v in nonZeroDict.keys():\n",
    "                nonZeroDict[v] = np.mean(nonZeroDict[v])\n",
    "            else:\n",
    "                nonZeroDict[v] = 0\n",
    "        seriesList.append(pd.Series(nonZeroDict, name=theseVals.name))\n",
    "    return(pd.DataFrame(seriesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0960f3-4f51-4c6d-8269-8a201c8de4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_plot(thisData):\n",
    "    figure = plt.figure(figsize=(20,10))\n",
    "    figure.subplots_adjust(bottom=0.35)\n",
    "    \n",
    "    suffix = ['NOb_NOA', 'NOb_OA', 'Ob_NOA', 'Ob_OA']\n",
    "    suffix = ['Normal_BMI', 'Normal_BMI_OA', 'Obese_BMI', 'Obese_BMI_OA']\n",
    "    suffix = ['Obese_BMI', 'Obese_BMI_OA']\n",
    "#     print(pd.DataFrame(thisData))\n",
    "    # print('thisData')\n",
    "    # print(thisData)\n",
    "    \n",
    "    # for p, cols in enumerate([NOb_NOA_Cols, NOb_OA_Cols, Ob_NOA_Cols, Ob_OA_Cols]):\n",
    "    for p, cols in enumerate([Ob_NOA_Cols, Ob_OA_Cols]):\n",
    "        tempData = calc_nonZero_mean(thisData, cols)\n",
    "        pos = []\n",
    "        for n in range(len(thisData.index)):\n",
    "            # pos.append((n*4)+p+1)\n",
    "            pos.append((n*3)+p+1)\n",
    "        plt.boxplot(tempData.T, sym='-', labels=tempData.index+'_'+suffix[p], positions=pos)\n",
    "#         plt.boxplot(tempData.T, sym='-', labels='FOXP3'+'_'+suffix[p], positions=pos)\n",
    "\n",
    "        for i,j in enumerate(tempData.index):\n",
    "            \n",
    "\n",
    "            y = tempData.loc[j]\n",
    "            colours = [colourList[0] if v in AOIDict['NOb_NOA'] else colourList[1] if v in AOIDict['NOb_OA'] else colourList[2] if v in AOIDict['Ob_NOA'] else colourList[3] for v in y.index]\n",
    "            y = y.values\n",
    "            # x = np.random.normal(1+p+(i*4), 0.1, len(y))\n",
    "            x = np.random.normal(1+p+(i*3), 0.1, len(y))\n",
    "            for i in range(len(x)): \n",
    "                plt.plot(x[i], y[i], c=colours[i], marker='.')\n",
    "        plt.xticks(rotation = 90)\n",
    "        # plt.xlabel=list(endogNorm.index[startIdx:endIdx])\n",
    "    #     plt.xlabel=['CD80', 'CD66b', 'PD-L2', 'GITR', 'Phospho-GSK3B (S9)']\n",
    "\n",
    "    plt.title('Normalised Probe Values (Log2 transformed)', size=36)\n",
    "    plt.ylabel('Log2 probe value', size=24)\n",
    "    plt.tight_layout(h_pad=2)\n",
    "    plt.savefig(file[:-4] + '_Folicles.svg')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753b5a8-f9d5-496d-8f00-019f0f215943",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b148fd-ab52-468e-9a3f-92001fd1fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB = ['CD20','PD-1', 'CD3', 'CD4', 'CD8', 'CTLA4', 'CD45RO', 'FOXP3', '4-1BB', 'LAG3', 'Tim-3', 'GITR', 'CD127', 'CD25', 'CD27']\n",
    "\n",
    "# KeepNames = ['IP_TMA_OA_2022_07_28_036_Full.ROI',\n",
    "#  # 'IP_TMA_OA_2022_07_28_073_Full.ROI',\n",
    "#  # 'IP_TMA_OA_2022_07_28_074_Full.ROI',\n",
    "#  'IP_TMA_OA_2022_07_28_042_Full.ROI',\n",
    "#  'IP_TMA_OA_2022_07_28_051_Full.ROI',\n",
    "#  'IP_TMA_OA_2022_07_28_053_Full.ROI',\n",
    "#  'IP_TMA_OA_2022_07_28_086_Full.ROI',\n",
    "#  'IP_TMA_OA_2022_07_28_092_Full.ROI']\n",
    "\n",
    "\n",
    "KeepNames = ['IP_TMA_OA_2022_07_28_073_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_074_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_042_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_051_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_053_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_086_Full ROI',\n",
    " 'IP_TMA_OA_2022_07_28_092_Full ROI']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfd1db-dab8-4b9d-85a1-58e2893f2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090ea2e-ec8e-42b1-8df3-44445f815777",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF = pd.read_csv(file)\n",
    "tempDF.columns = [x.replace('.',' ') for x in tempDF.columns]\n",
    "sampleInfoTemp = sampleInfo.copy()\n",
    "sampleInfoTemp.columns = [x.replace('.',' ') for x in sampleInfoTemp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c51b21-22fb-4b06-b130-f3f1ee272b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfoTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3464ee-b0d9-4e77-8ba8-8c4e8dd46af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempInfo = sampleInfoTemp.loc[:,KeepNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ebd7-5cb6-4645-811d-6b7e0f25473e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tempInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a925b1-928f-4d90-81ba-45238ed4c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOb = tempInfo.loc[:,sampleInfoTemp.loc['Obese'] == 'NonObese']\n",
    "Ob = tempInfo.loc[:,sampleInfoTemp.loc['Obese'] == 'Obese']\n",
    "\n",
    "NOb_NOA_Cols = NOb.loc[:,NOb.loc['arthritis'] == 'NOA'].columns\n",
    "NOb_OA_Cols = NOb.loc[:,NOb.loc['arthritis'] == 'OA'].columns\n",
    "\n",
    "Ob_NOA_Cols = Ob.loc[:,Ob.loc['arthritis'] == 'NOA'].columns\n",
    "Ob_OA_Cols = Ob.loc[:,Ob.loc['arthritis'] == 'OA'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e8932-9921-4a3b-bd1f-f9190eed21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOIDict = {}\n",
    "suffix = ['NOb_NOA', 'NOb_OA', 'Ob_NOA', 'Ob_OA']\n",
    "for i, cols in enumerate([NOb_NOA_Cols, NOb_OA_Cols, Ob_NOA_Cols, Ob_OA_Cols]):\n",
    "    AOIDict[suffix[i]] = list(sampleInfoTemp.loc['TMA_Core',cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f21aad-c05d-4a45-bdaf-6964ef8a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "colourList = [[   1, 0.5019607843137255, 0.0],\n",
    "              [0.3333333333333333, 0.6274509803921569,0.984313725490196],\n",
    "              [0.7215686274509804,0.33725490196078434,0.8431372549019608],\n",
    "              [0,1, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852366f-99dd-46ec-833f-dcaded908411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0dbdbc-a3c6-47d4-9114-c91c7512f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF = tempDF.loc[:,tempDF.columns[7:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84888a-f852-4d85-a70b-1bcb4a58dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempDF.loc[TB, KeepNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf8f13-e26c-40d8-a600-3ede5c14aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfoTemp.loc[['Obese','arthritis'],KeepNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e106967-4545-499e-985c-daf22c1ca0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1845ae-45cb-4372-9085-bda31c1629ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempDF.loc[TB, KeepNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113bb71-eec2-4511-8a56-342869c8e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_plot(np.log2(tempDF.loc[TB, KeepNames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62926f9a-28cb-4b1c-a25f-fbf4252c6960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c78d-8291-4c82-8c00-c0cf2adb85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762e58a-3b27-4886-86bb-6d08419213d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5ba93-cb50-41a4-8ee3-cab2d570eb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6493c1e-dd7c-40c2-993b-c29b0371277f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f32bf7-1dea-4d6b-aa15-04b56083d449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7b30d-ef86-47a2-afd7-d8ce49bd0d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataPath = '../../../Nanostring/projects/.../DSP_Protein_Data/'\n",
    "dataPath = configDict['rootDir']\n",
    "data = pd.read_csv(os.path.join(dataPath,'HK_Geo_Mean_Normalised.csv'), index_col = 0)\n",
    "probeFilter = pd.read_csv(os.path.join(dataPath,'Probe_Filter.csv'), index_col = 0)\n",
    "sampleInfo = pd.read_csv(os.path.join(dataPath,'Sample_Info.csv'), index_col = 0)\n",
    "\n",
    "# dataPath = '../../../Nanostring/projects/.../EdgeR/EdgeR_normData.tsv'\n",
    "dataPath = os.path.join(configDict['rootDir'], normPath, normFile)\n",
    "\n",
    "data = pd.read_csv(dataPath, index_col = 0)\n",
    "\n",
    "# dataPath = '../../../Nanostring/projects/.../DSP_Protein_Data/'\n",
    "dataPath = configDict['rootDir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46727c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7886714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(os.path.join(dataPath,'Annotation template file-1a_wells_02.xlsx'))\n",
    "\n",
    "print(wb.sheetnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d059dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb['Annotation template']\n",
    "\n",
    "segments = [[y.value for y in x] for x in ws[ws.calculate_dimension()]]\n",
    "df = pd.DataFrame(segments)\n",
    "\n",
    "\n",
    "rowLabels = df.iloc[1:,0]\n",
    "colLabels = df.iloc[0,1:]\n",
    "annotations = df.iloc[1:,1:]\n",
    "rowLabels += '_'\n",
    "rowLabels += df.iloc[1:,1]\n",
    "rowLabels += '_Full ROI'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad61d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bc35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15288fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations = pd.DataFrame(annotations.values, index=rowLabels, columns=colLabels)\n",
    "\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "# sampleAnnotations.set_index(0, drop=True, inplace=True)\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "# sampleAnnotations.set_index('Scan name', drop=True, inplace=True)\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations = sampleAnnotations.join(sampleInfo.T,lsuffix='Drop').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations.drop(labels=[x for x in sampleAnnotations.index if x.endswith('Drop')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd77cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo = sampleAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fe771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461799ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(arr):\n",
    "         \n",
    "    '''\n",
    "    This function standardize an array, its substracts mean value, \n",
    "    and then divide the standard deviation.\n",
    "    \n",
    "    param 1: array \n",
    "    return: standardized array\n",
    "    '''    \n",
    "    rows, columns = arr.shape\n",
    "    \n",
    "    standardizedArray = np.zeros(shape=(rows, columns))\n",
    "    tempArray = np.zeros(rows)\n",
    "    \n",
    "    for column in range(columns):\n",
    "        \n",
    "        mean = np.mean(X[:,column])\n",
    "        std = np.std(X[:,column])\n",
    "        tempArray = np.empty(0)\n",
    "        \n",
    "        for element in X[:,column]:\n",
    "            \n",
    "            tempArray = np.append(tempArray, ((element - mean) / std))\n",
    " \n",
    "        standardizedArray[:,column] = tempArray\n",
    "    \n",
    "    return standardizedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "\n",
    "### I'm not sure that the transpose is what i want here. The data is the wrong shape and pc's seems to be being calculated for proteins instead of samples\n",
    "X = endogNorm.transpose().values\n",
    "# X = endogNorm.values\n",
    "### Try to get pc's for samples\n",
    "# X = endogNorm.values\n",
    "\n",
    "## ??? With transpose makes PCA for effect of variables on smaples, without makes PCA for effects of variables on protein expression levels\n",
    "###^^^ Maybe the other way round?\n",
    "\n",
    "\n",
    "\n",
    "X_cols = endogNorm.columns\n",
    "print(X_cols.shape)\n",
    "y = endogNorm.index\n",
    "print(y.shape)\n",
    "X = standardize_data(X)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df305d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the covariance matrix\n",
    "\n",
    "covariance_matrix = np.cov(X.T)\n",
    "# covariance_matrix = np.cov(X)\n",
    "\n",
    "\n",
    "\n",
    "print(covariance_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e99c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using np.linalg.eig function\n",
    "\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "print(\"Eigenvector: \\n\",eigen_vectors,\"\\n\")\n",
    "print(\"Eigenvalues: \\n\", eigen_values, \"\\n\")\n",
    "print(eigen_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dbfd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigenDF = pd.DataFrame(eigen_vectors, index=[endogNorm.index], columns=[endogNorm.index])\n",
    "# eigenDF = pd.DataFrame(eigen_vectors, index=[endogNorm.columns], columns=[endogNorm.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the explained variance on each of components\n",
    "\n",
    "\n",
    "variance_explained = []\n",
    "for i in eigen_values:\n",
    "     variance_explained.append((i/sum(eigen_values))*100)\n",
    "        \n",
    "print(variance_explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b83e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying components that explain at least 95%\n",
    "\n",
    "cumulative_variance_explained = np.cumsum(variance_explained)\n",
    "print(cumulative_variance_explained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d49f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_explained = [np.float64(x) for x in cumulative_variance_explained]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc40023",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_explained[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca42949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the eigenvalues and finding the \"elbow\" in the graphic\n",
    "\n",
    "\n",
    "sns.lineplot(x = [i for i in range(len(cumulative_variance_explained))], y=cumulative_variance_explained)\n",
    "# plt.xlabel(\"Number of components\")\n",
    "# plt.ylabel(\"Cumulative explained variance\")\n",
    "# plt.title(\"Explained variance vs Number of components\")\n",
    "\n",
    "\n",
    "\n",
    "# ToDo:\n",
    "# Add lines for 95% variance, and number of components describing at least 95% of variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using two first components (because those explain more than 95%)\n",
    "\n",
    "projection_matrix = (eigen_vectors.T[:][:50]).T\n",
    "print(projection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['g' if x.split('_')[-1] == 'Tumour' else 'r' for x in X_cols]\n",
    "colours = ['g' if x.split('_')[-1] == 'Tumour' else 'r' if x.split('_')[-1] == 'Immune' else 'purple' for x in X_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78105cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont think this gives relevant info. projection matrix needs to be combined with original data to see effects of components on patients\n",
    "\n",
    "plt.scatter([x[0] for x in projection_matrix], [x[1] for x in projection_matrix])#, c=colours)\n",
    "\n",
    "projection_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x[2] for x in projection_matrix], [x[1] for x in projection_matrix])#, c=colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87721766",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x[2] for x in projection_matrix], [x[3] for x in projection_matrix])#, c=colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the product of original standardized X and the eigenvectors \n",
    "\n",
    "\n",
    "X_pca = X.dot(projection_matrix)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e99136",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383154c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fe4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagDF = pd.DataFrame( data=[x.split(',') for x in sampleInfo.loc['Segment tags']], index=sampleInfo.columns, columns=['Obese','Arth','Patellar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05005bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfo = pd.concat([sampleInfo,tagDF.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c206dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5523ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inforSortedIndex = sampleInfo.sort_values(by=['Obese','arthritis','TMA_Core'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b7c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe99ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f507eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add umap / tSNE analysis here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9bd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eac82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
