{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from scipy import stats as stats\n",
    "from copy import copy as copy\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.table import Table\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27332690-7fd2-4b8d-9e53-d80b718792e2",
   "metadata": {},
   "source": [
    "# Define/Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a113e7-ed49-48a5-bc52-ee7338018606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.plotting import(volcanoPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf92aa-6863-4d82-a4ca-8297583e6796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutput = False\n",
    "# writeOutput = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4bf47-c513-4961-8915-b840ab7964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoRunProject = True\n",
    "# autoRunProject = False\n",
    "\n",
    "\n",
    "if autoRunProject:\n",
    "    with open('projects.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if ((not line.startswith('#')) and (not line.strip()=='')):\n",
    "                subfolder = line\n",
    "else:\n",
    "    subfolder = input(\"Enter the name of the working folder (Must be same level as code folder)\")\n",
    "\n",
    "print(subfolder)\n",
    "\n",
    "os.chdir(\"../\" + subfolder)\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee0f5a-66ee-4425-a491-3c8cabc4308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedc686-0ed5-4c88-82be-d9d5e9722861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paths from config file\n",
    "configDict = {\n",
    "    'rootDir': '',\n",
    "    'initialDataPath' : '',\n",
    "    'QCDataPath' : '',\n",
    "    'labWorksheet01Path':'',\n",
    "    'sampleInfoFile' : '',\n",
    "    'projectName':'',\n",
    "    'selectedData': []\n",
    "}\n",
    "\n",
    "with open('./config.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if not line.startswith('#'):\n",
    "            line = line.strip()\n",
    "            fields = line.split(':')\n",
    "\n",
    "            if fields[0].strip()=='initialDataPath':\n",
    "                configDict[fields[0].strip()] = fields[1].strip().strip('\\'')\n",
    "            elif fields[0].strip()=='probeThresholdIdx':\n",
    "                configDict[fields[0].strip()] = int(fields[1].strip().strip('\\''))\n",
    "            elif fields[0].strip()=='selectedData':\n",
    "                tempList = fields[1].strip().strip('\\'').split(',')\n",
    "                tempList = [x.strip() for x in tempList]\n",
    "                configDict['selectedData'] = tempList\n",
    "            else:\n",
    "                configDict[fields[0].strip()] = fields[1].strip().strip('\\'')\n",
    "## ToDo: Add checks to ensure that minimal fields have been populated. Raise errors or warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e660655-fc4b-4e7e-b8bc-61cee9bedbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "configDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3c94b-0812-4df2-bec7-894855e9c354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b7cd9e9-2dec-40fe-b777-fe5c59213909",
   "metadata": {},
   "source": [
    "# Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2cd9a-bfe9-4961-bccb-975ff8a17629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo:\n",
    "# add sample info file details into config file in previous notebook\n",
    "# sampleInfo_with_Wells.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff87a1-6e8d-4bf4-b09f-90d7268fbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Should initial filtering be done using none-mean-HKGeoMean normalised data. Using a type of background subtraction for filtering would bias towards removing noisy or low expressing samples. Removing these may give more accurate estimates of real probe values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047948f-3a4c-4ab4-91e9-89d7cb9a4031",
   "metadata": {},
   "source": [
    "## Read-in nanostring normalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8e6e2-968e-4d2d-ae5c-33837cbcfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "normDir = os.path.join(configDict['rootDir'], 'Normalisation')\n",
    "# print(normDir)\n",
    "QCDataFile = [f for f in os.listdir(normDir) if (f.startswith('QC') and f.endswith('RUV.csv'))][0]\n",
    "print(QCDataFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b41968-1b35-4b37-9efc-0def51874aa6",
   "metadata": {},
   "source": [
    "### Sort samples and probes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc92ba-726f-4c20-adf6-4f03b5d13227",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF = pd.read_csv(os.path.join(normDir, QCDataFile), index_col=0)\n",
    "QCDataDF.columns = [x.replace(' ','.') for x in QCDataDF.columns]\n",
    "QCDataDF.columns = [x.replace('-','.') for x in QCDataDF.columns]\n",
    "\n",
    "codeClass = QCDataDF.loc[:,'Code.Class']\n",
    "\n",
    "probeOrder = QCDataDF.index[8:]\n",
    "sampleOrder = QCDataDF.columns[1:]\n",
    "\n",
    "# sampleOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84987a1-a0ee-436c-9a7c-c7aa894d7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafa6fb-a942-40d9-b81e-961db1771d62",
   "metadata": {},
   "source": [
    "## Read-in sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4052103-51e3-4199-acbc-71db02aa976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF.columns = [x.replace(' ','.') for x in QCDataDF.columns]\n",
    "QCDataDF.columns = [x.replace('#','.') for x in QCDataDF.columns]\n",
    "QCDataDF.columns = [x.replace('/','.') for x in QCDataDF.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e316be-7c52-45d2-990e-773ff4e41dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591a1ce-88e5-4f0f-ad05-dcf59da915cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a9faf-67fa-48f8-8678-df5103f47115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec76054-4052-40c7-ae2a-fd9a8e6bdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo = pd.read_csv(os.path.join(configDict['rootDir'], configDict['sampleInfoFile']), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55d350-db62-435e-8f64-38953411ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd3a45-f39d-48e6-a0d6-f7905bb78599",
   "metadata": {},
   "outputs": [],
   "source": [
    "colTemp = sampleInfo.columns\n",
    "colTemp = [x.replace(' ','.') for x in colTemp]\n",
    "colTemp = [x.replace('-','.') for x in colTemp]\n",
    "sampleInfo.columns = colTemp\n",
    "\n",
    "\n",
    "sampleInfo = sampleInfo.loc[:,sampleOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7973c7-f93c-4c15-81b9-05d455a2a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo.columns = [x.replace(' ','.') for x in sampleInfo.columns]\n",
    "sampleInfo.columns = [x.replace('#','.') for x in sampleInfo.columns]\n",
    "sampleInfo.columns = [x.replace('/','.') for x in sampleInfo.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced723f-ab09-48c8-95f5-e043f40b84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2263590-3c25-4042-aed2-2f61000f9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors = input('enter factors to be used for groups to check probe expression. separate multiple factors by a comma')\n",
    "factors = configDict['selectedData']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a4cfb-fd32-4012-96e3-da2e747b4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dictionary to hold factors for group analysis\n",
    "factorDict = {}\n",
    "factorDict2 = {}\n",
    "\n",
    "for f in factors:\n",
    "    entries = list(set(sampleInfo.loc[f].values))\n",
    "    print(entries)\n",
    "    factorDict[f] = entries\n",
    "    factorDict2[f] = {}\n",
    "    for e in entries:\n",
    "        factorDict2[f][e] = sampleInfo.columns[sampleInfo.loc[f] == e]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c3948-4d71-42db-a75c-2075b34ff593",
   "metadata": {},
   "outputs": [],
   "source": [
    "factorDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3f408-d8f6-45bd-88fc-2d5eda009cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "factorDict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157863bf",
   "metadata": {},
   "source": [
    "# Visualise Nanostring Norm results and choose samples to be kept for final normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5626ade-d34f-4e2c-95b4-d417a8d507e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "configDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99611a-68a5-4b53-96af-924a4b2c344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8959428-c042-4f36-a5be-77f8de8df3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pow(2, QCDataDF.drop(labels=['Code.Class'],axis=1).loc[['SMA','Fibronectin'],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537110be-bfb2-4cd9-a1bf-bf8e3328ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(normDir, 'NSNorm'))\n",
    "files = sorted(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad704030-9864-4cca-b867-5bdeab0317f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08244ab1-60b1-4754-aa27-f32b87c49aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "probeOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a253e3-1ead-49c4-9168-c5c1e38bae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleOrder = [x.replace(' ','.') for x in sampleOrder]\n",
    "sampleOrder = [x.replace('#','.') for x in sampleOrder]\n",
    "sampleOrder = [x.replace('/','.') for x in sampleOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 14\n",
    "height = 11\n",
    "\n",
    "fig, axs = plt.subplots(height, width, figsize=[40,25])\n",
    "# fig.suptitle('Nanostring Normalisation heatmaps')\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        fileIdx = x + y*width\n",
    "        tempDF = pd.read_csv(os.path.join(normDir, 'NSNorm',files[fileIdx]), index_col=0)\n",
    "#         axs[y][x].matshow(np.log2(tempDF + 1), aspect = 'auto', cmap='coolwarm')\n",
    "        axs[y][x].matshow(np.log2(tempDF.loc[probeOrder,sampleOrder] + 1), cmap='coolwarm')\n",
    "        axs[y][x].set_xticks([])\n",
    "        axs[y][x].set_yticks([])\n",
    "        axs[y][x].set_title(files[fileIdx][:-4])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('NSNorm.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae029c-b310-4b63-8252-fe984826d89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "258147fe-2774-4613-9cc1-00ecdac9f6dc",
   "metadata": {},
   "source": [
    "# Threshold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e0f1e-8ecc-444a-87de-0e14e59efd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlSet = set(['HYB-NEG', 'HYB-POS', 'Rb IgG', 'Ms IgG2a', 'Ms IgG1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f322d02-dc69-4133-8668-f9b85e4a6ec7",
   "metadata": {},
   "source": [
    "### Threshold probes and drop low or null expressing probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c26df7-a10e-41f0-ae86-c380d6819df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Add in a variable called  thresholdData to hold data for comparison at thresholding stage. This will be read from one of the normalised files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d5975-9c6f-4e0a-bc8f-ee54d9a9e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Examine which normalised data should be used for thresholding. Does it make a difference if background correction has been performed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71306fe6-f817-4978-94d6-c4fd747e9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdData = pd.read_csv(os.path.join(normDir, 'NSNorm',files[51]), index_col=0) # none_mean_lowCVGeoMean\n",
    "# thresholdData = pd.read_csv(os.path.join(normDir, 'NSNorm',files[24]), index_col=0) #None_None_HKGeoMean\n",
    "thresholdData.columns = [x.replace(' ','.') for x in thresholdData.columns]\n",
    "thresholdData.columns = [x.replace('-','.') for x in thresholdData.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981d6d9-1b03-4056-a627-ed6d3703ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Check that thresholding os not too restrictive. Should allow probes to be kept if they are expressed in more than half of any sub group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1b884-949e-4d45-8a5b-ff7b23ad35ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 1.5\n",
    "expPropCutOff = 0.5\n",
    "SamplePropCutOff = 0.5\n",
    "\n",
    "dropList = []\n",
    "\n",
    "dropSetTemp = []\n",
    "\n",
    "for f in factorDict2.keys():\n",
    "    print(f)\n",
    "    for g in factorDict2[f].keys():\n",
    "        print(g)\n",
    "        print(factorDict2[f][g])\n",
    "        groupLen = len(factorDict2[f][g])\n",
    "        # print(groupLen)\n",
    "        passThreshold = (thresholdData[factorDict2[f][g]]>threshold).sum(axis=1)\n",
    "        # print(passThreshold)\n",
    "        passThreshProp = (passThreshold/groupLen) < expPropCutOff\n",
    "        # print(passThreshProp)\n",
    "        failIdx = thresholdData.index[passThreshProp]\n",
    "        print(failIdx)\n",
    "        print(len(failIdx))\n",
    "\n",
    "        if (len(failIdx) > 0):\n",
    "            dropList.extend(list(failIdx))\n",
    "            dropSetTemp.append(list(failIdx))\n",
    "        # print(thresholdData.index[((thresholdData[factorDict2[f][g]]>2).sum(axis=1)/groupLen) < 0.5])\n",
    "\n",
    "dropList = list(set(dropList) - controlSet)\n",
    "print(dropList)\n",
    "print(dropSetTemp)\n",
    "\n",
    "# dropSet = set(tuple(x) for x in dropSetTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5374133-f369-40b9-89a5-1b2bfd298002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropSet = set(dropSetTemp[0])\n",
    "\n",
    "for x in range(1,len(dropSetTemp)):\n",
    "    # print(x)\n",
    "    dropSet = dropSet & set(dropSetTemp[1])\n",
    "\n",
    "dropSet = dropSet - controlSet\n",
    "# dropSet\n",
    "dropList = list(dropSet)\n",
    "# dropList\n",
    "QCDataDF = QCDataDF.drop(index=dropList)\n",
    "\n",
    "\n",
    "codeClass = codeClass[QCDataDF.index]\n",
    "print(codeClass)\n",
    "\n",
    "\n",
    "print(len(dropList))\n",
    "print(dropList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb708be6-4e27-48d8-ae7b-929194bf72b8",
   "metadata": {},
   "source": [
    "### Threshold samples and drop low or null expressing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bb8e0-29ac-468a-a616-3a9db51eeb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropSamples = list(QCDataDF[QCDataDF.columns[1:]].T[(QCDataDF[QCDataDF.columns[1:]]>threshold).sum(axis=0)/len(QCDataDF.index) < SamplePropCutOff].index)\n",
    "print('dropSamples : ')\n",
    "print(dropSamples)\n",
    "QCDataDF = QCDataDF.drop(labels=dropSamples, axis=1)\n",
    "# QCDataDF = QCDataDF.drop(index=dropSamples)\n",
    "# QCDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b662b-5dd4-4bae-ab21-bd940007f192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QCDataDF.index.name = 'Name'\n",
    "QCDataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5b52a-7ce9-4bca-9194-07b0fb285193",
   "metadata": {},
   "source": [
    "- export data after dropping probes and samples due to low expression\n",
    "- re-run NSNorm\n",
    "- Continue with viewing data and QC of normalised data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3ef0a-12a8-468a-b307-43b110019ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Log transform needs to be reversed before use in EdgeR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66592419-5f4d-490f-9163-b6ab06663413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pow(2, QCDataDF.drop(labels=['Code.Class'], axis=1).loc[['SMA','Fibronectin'],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6df1c-c648-4578-9684-782820a5a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(2,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734165a-d84e-4197-bcb6-0ba8fed869a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc6f31-0fbc-45da-8cce-35b695b31936",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = configDict['projectName']\n",
    "\n",
    "qcDropCSV = 'QC_' + project + '_RUV_Dropped.csv'\n",
    "\n",
    "writeOutput = True\n",
    "if writeOutput:\n",
    "    QCDataDF.to_csv(os.path.join(normDir, qcDropCSV))\n",
    "writeOutput= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bff30f-9ae9-4af0-aa37-2f1ced053a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'Rscript ../DSP_EDA_Protein/NSNorm.R -d ' + normDir + ' -s NSNormDropped -f ' + qcDropCSV\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef69a7-81bf-424f-9261-88d74d6c47ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4eb2d-6379-4f25-a3d7-051aea7a45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(normDir, 'NSNormDropped'))\n",
    "files = sorted(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee4c9d-f900-49ba-94fa-dc465eeb02fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width = 6\n",
    "height = 14\n",
    "\n",
    "fig, axs = plt.subplots(height, width, figsize=[40,25])\n",
    "# fig.suptitle('Nanostring Normalisation heatmaps')\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        fileIdx = x + y*width\n",
    "        tempDF = pd.read_csv(os.path.join(normDir, 'NSNormDropped',files[fileIdx]), index_col=0)\n",
    "#         axs[y][x].matshow(np.log2(tempDF + 1), aspect = 'auto', cmap='coolwarm')\n",
    "        # axs[y][x].matshow(np.log2(tempDF.loc[probeOrder,sampleOrder] + 1), cmap='coolwarm')\n",
    "        axs[y][x].matshow(np.log2(tempDF + 1), cmap='coolwarm')\n",
    "        axs[y][x].set_xticks([])\n",
    "        axs[y][x].set_yticks([])\n",
    "        axs[y][x].set_title(files[fileIdx][:-4])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# fig.show()\n",
    "fig.savefig('NSNormDropped.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba7570-4506-4a27-ab10-1e2ccd76f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44556952-abf6-4636-900b-7bae0a8a3baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d317cf-87a3-4f22-844f-b9e932dfd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop samples from sample info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26740046-5f61-4ba4-b361-ed0c11a4079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b37d0-1d8a-4889-b660-ddd51b65b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate groups for EdgeR analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb163cf-255c-4853-ab51-ad37f68106b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = noneMeanHKDF > 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noneMeanHKDF = pd.read_csv(os.path.join(normDir, 'NSNorm',files[27]), index_col=0)\n",
    "noneMeanHKDF = pd.read_csv(os.path.join(normDir, 'NSNormDropped',files[27]), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noneMeanHKDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupedExpressedIndex = noneMeanHKDF.loc[probeOrder].loc[((noneMeanHKDF > 0 ).sum(axis = 1) / len(noneMeanHKDF.columns) > 0.33333)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a768cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupedExpressedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390150d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(groupedExpressedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31255ab5-9a49-431e-83fa-b342d88533c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac7ba7-b419-45d9-97da-f1d843fbd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCData = pd.read_csv(os.path.join(normDir, QCDataFile), index_col=0)\n",
    "\n",
    "QCData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a30752",
   "metadata": {},
   "source": [
    "# Run EdgeR analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824bcb2-81a9-4343-9da8-1296d8795e9f",
   "metadata": {},
   "source": [
    "Write comparisons to a text file that will be parsed by the r script\n",
    "\n",
    "In form of factor.variable, factor.variable2, comparisonName\n",
    "1 comparison per line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bdde9-9f71-459d-b45f-fe4ae52d9749",
   "metadata": {},
   "source": [
    "  make_option(c(\"-d\", \"--datadir\"), type=\"character\", default=NULL, \n",
    "              help=\"dataset file name\", metavar=\"character\"),\n",
    "  make_option(c(\"-f\", \"--file\"), type=\"character\", default=NULL, \n",
    "              help=\"dataset file name\", metavar=\"character\"),\n",
    "  make_option(c(\"-e\", \"--exportdir\"), type=\"character\", default=\"NSNorm\", \n",
    "              help=\"dataset file name\", metavar=\"character\"),\n",
    "  make_option(c(\"-i\", \"--sampleinfo\"), type=\"character\", default=NULL, \n",
    "              help=\"dataset file name\", metavar=\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1536c2-134b-41a6-a02f-8a93b80504d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31a2673-b1c0-440a-a3b1-d19986a3c3b7",
   "metadata": {},
   "source": [
    "### extract potential factors for analysis from info file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021874d0-af03-4a0a-936d-72065e3ffe9c",
   "metadata": {},
   "source": [
    "### extract potential groups based on factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f30f6-8a8c-4fca-93d1-a7bd8400b96d",
   "metadata": {},
   "source": [
    "### Show group numbers for each of the comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc842f1-16a0-46fe-a006-5e78eb9c4b92",
   "metadata": {},
   "source": [
    "### Set up config file for EdgeR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2acb2f-d781-4ff3-99e0-a0a251c1e909",
   "metadata": {},
   "source": [
    "#### (Use helper notebook or uncomment code below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ba88c-c9b6-41b6-9504-93733b4bba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # groups = ['Broad_classification']\n",
    "# comps = [\n",
    "#     []\n",
    "# ]\n",
    "\n",
    "# compNames = []\n",
    "# for g in comps:\n",
    "#     ctemp = []\n",
    "#     for c in g:\n",
    "#         c = c.replace('.','_')\n",
    "#         c = c.replace(' - ','_vs_')\n",
    "#         ctemp.append(c)\n",
    "#     compNames.append(ctemp)\n",
    "\n",
    "# compNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65620684-b670-4037-a8f6-d444eeedaf7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outFile = 'EdgeR_Config.txt'\n",
    "\n",
    "# outLines = []\n",
    "# for g in range(len(groups)):\n",
    "#     groupLine = 'GROUP:' + groups[g]\n",
    "#     outLines.append(groupLine)\n",
    "    \n",
    "#     compLine = 'COMPARISON:'\n",
    "#     compNameLine = 'COMP_NAME:'\n",
    "#     for c in range(len(comps[g])):\n",
    "#         compLine += comps[g][c]\n",
    "#         compLine += ','\n",
    "#         compNameLine += compNames[g][c]\n",
    "#         compNameLine += ','\n",
    "    \n",
    "#     outLines.append(compLine)\n",
    "#     outLines.append(compNameLine)\n",
    "\n",
    "# with open(outFile, 'w') as o:\n",
    "#     o.write('\\n'.join(outLines))\n",
    "#     o.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078279a3-7f6e-4a86-8060-0d5ee160f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configDict['rootDir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ac1db-3744-40c9-9a0e-76c789e7dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d60a6-57e5-4973-8a2a-4189077360ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Ensure that EdgeR_config.txt has been populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7578a-5369-489b-96dc-8a52fdd95004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669cbfe-782f-4d7a-95ef-a256aedbf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normPath = os.path.join('Normalisation','NSNormDropped')\n",
    "normPath = os.path.join('Normalisation','NSNorm')\n",
    "print(normPath)\n",
    "\n",
    "# normFile = 'NanoStringNorm_52_none_mean_low.cv.geo.mean.csv'\n",
    "# normFile = 'NanoStringNorm_49_none_none_low.cv.geo.mean.csv'\n",
    "normFile = 'NanoStringNorm_25_none_none_housekeeping.geo.mean.csv'\n",
    "# normFile = 'NanoStringNorm_13_none_none_housekeeping.sum.csv'\n",
    "print(normFile)\n",
    "\n",
    "exportdir = 'EdgeR'\n",
    "runname = 'NS' + normFile[10:17]\n",
    "# runname = 'temp_NS' + normFile[10:17]\n",
    "exportdir = os.path.join('EdgeR', runname)\n",
    "\n",
    "sampleinfoFile = 'sampleInfo_with_Wells.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec14fd1-697b-4c1e-864b-5f67ae84e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir))\n",
    "except FileNotFoundError:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir.split('/')[0]))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(os.path.join(configDict['rootDir'], exportdir))\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7afee-7385-4d18-aa88-4925d2058bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2737f28-3834-454b-a536-62351ebab936",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bda3f-ea49-4a00-93fe-c5b1e899a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to handle dropped samples that may still be present in sampleinfoFile. Could be handled with another file, or by removing samples within R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ba967-0c9c-40bb-9012-af5be8369e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# cmd = 'Rscript EdgeR.R -c ' + os.getcwd() + ' -d ' + configDict['rootDir'] + ' -n ' + normPath + ' -f ' + normFile + ' -e ' + exportdir + ' -r ' + runname  + ' -i ' + sampleinfoFile\n",
    "cmd = 'Rscript ../DSP_EDA_Protein/EdgeR.R -c ' + os.getcwd() + ' -d ' + configDict['rootDir'] + ' -n ' + normPath + ' -f ' + normFile + ' -e ' + exportdir + ' -i ' + sampleinfoFile\n",
    "print(cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fdfc8-d3eb-4274-83aa-b30a07b413b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75803582",
   "metadata": {},
   "source": [
    "# Convert MD Plots to Volcano Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently done in a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join(configDict['rootDir'],exportdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files to run\n",
    "\n",
    "dataPath = os.path.join(configDict['rootDir'],exportdir,)\n",
    "\n",
    "filesMaster = []\n",
    "\n",
    "for root, folder, files in os.walk(dataPath):\n",
    "    print(root)\n",
    "    print(folder)\n",
    "    print(files)\n",
    "\n",
    "    files = [os.path.join(root, f) for f in files if (f.endswith('.csv') and f.startswith('MD_plot'))]\n",
    "    filesMaster.extend(files)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639af0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run volcano plots\n",
    "sigGenes = []\n",
    "\n",
    "# TMESigGenes = []\n",
    "# TumourSigGenes = []\n",
    "\n",
    "for file in filesMaster:\n",
    "    # subGenes = volcanoPlotpVal(dataPath, file)\n",
    "    if not (file[-7:-4] == '_tr'):\n",
    "        subGenes = volcanoPlot(dataPath, file, pVal=True)\n",
    "        sigGenes.extend(subGenes)\n",
    "    \n",
    "# print(sigGenes)\n",
    "# print(set(sigGenes))\n",
    "sigGenes = list(set(sigGenes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bebb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40968b10-33ba-4ea0-a66c-62f79903e7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "610bb0c4-16f0-4e72-be5d-d2726f2396d6",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def3a6-a389-4404-99af-dc7828c4d6f6",
   "metadata": {},
   "source": [
    "### Plot heatmaps and dendrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8021a6-8ff3-46ee-9493-2a2c812e9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Ensure heatmaps are using relevant normalised data. Read data from NSNorm or EdgeR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1022dae-5232-429c-9f57-19a6e6860fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCData.drop(labels=['Code.Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b3a36-1062-4f1e-897a-13d86f859145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "        \n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendro = dendrogram(linkage_matrix, **kwargs)\n",
    "    return(dendro['ivl'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d8ae6-5718-42ee-87e6-f827348174ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting distance_threshold=0 ensures we compute the full tree.\n",
    "# # model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "# model = AgglomerativeClustering(n_clusters=None, affinity='euclidean', memory=None, connectivity=None, compute_full_tree=True, linkage='ward', distance_threshold=0.1, compute_distances=True)\n",
    "\n",
    "# model = model.fit(QCData.drop(labels=['Code.Class'], axis=1).T)\n",
    "\n",
    "# # print(model. feature_names_in_)\n",
    "# # print(model. children_)\n",
    "# # print(model. labels_)\n",
    "# plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# # plot the top three levels of the dendrogram\n",
    "# labels = plot_dendrogram(model, truncate_mode=None, p=5)\n",
    "# # plot_dendrogram(model, truncate_mode=False)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.savefig('dendrogram.svg')\n",
    "# plt.show()\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4aa60-e3b2-41d1-b7de-d16b8af35ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset dataframe to contain only significant probes and relevant AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da321f-cb5e-43de-add5-ff9d4747ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_colours(AOINames, vars=False, tempVarLookup=False):\n",
    "    colourArray = []\n",
    "    if (vars == False):\n",
    "        vars = ['Obese', 'arthritis']\n",
    "    if (tempVarLookup == False):\n",
    "        tempVarLookup = {'NonObese':0.1,\n",
    "                     'Obese':0.2,\n",
    "                     'NOA':0.3,\n",
    "                     'OA':0.4,\n",
    "    }\n",
    "\n",
    "    AOINames = [x.replace(' ','.') for x in AOINames]\n",
    "    for v in vars:\n",
    "        tempVarNames = sampleInfo.loc[v,AOINames].values\n",
    "        colours = [tempVarLookup[x] for x in tempVarNames]\n",
    "        colourArray.append(colours)\n",
    "    \n",
    "    return(colourArray)\n",
    "# colourArray = get_var_colours()\n",
    "# colourArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073376bb-db7b-47ed-992e-feed691ee709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendroModel = AgglomerativeClustering(n_clusters=None, \n",
    "                                # affinity='euclidean', \n",
    "                                # metric='euclidean', \n",
    "                                metric='cosine', \n",
    "                                memory=None, \n",
    "                                connectivity=None, \n",
    "                                compute_full_tree=True, \n",
    "                                # linkage='ward', \n",
    "                                linkage='single', \n",
    "                                # linkage='complete', \n",
    "                                distance_threshold=0.1, \n",
    "                                compute_distances=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb21a1b-1768-4809-b4aa-b557324f0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo : Add linkage map from cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54678fc5-f8a4-4b89-b3f7-b1fecd616f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_AOIs(fileName):\n",
    "    # Extract subpopulation attributes from file name\n",
    "    fields = fileName[:-4].split('_')\n",
    "    fields.remove('MD')\n",
    "    fields.remove('plot')\n",
    "    # print(fields)\n",
    "    vsIDX = fields.index('vs')\n",
    "    # print(vsIDX)\n",
    "    numIDXs = [x for x in range(vsIDX)]\n",
    "    denomIDXs = [x for x in range(vsIDX+1,len(fields))]\n",
    "    # print('numIDXs')\n",
    "    # print(numIDXs)\n",
    "    # print('denomIDXs')\n",
    "    # print(denomIDXs)\n",
    "    AOISuperSets = [[],[]]\n",
    "    # factorLookup = {'Secondary':'Broad_classification',\n",
    "    #                 'Primary':'Broad_classification'}\n",
    "    factorLookup = {'IIA':'Histo_Stage',\n",
    "                    'IIB':'Histo_Stage',\n",
    "                    'IA':'Histo_Stage',\n",
    "                    'IV':'Histo_Stage',\n",
    "                    'Segment1':'Segment_Name',\n",
    "                    'Segment2':'Segment_Name',\n",
    "                   }\n",
    "    for i, IDXs in enumerate([numIDXs,denomIDXs]):\n",
    "        for idx in IDXs:\n",
    "            factor = fields[idx]\n",
    "            # print('factor')\n",
    "            # print(factor)\n",
    "            factorType = factorLookup[factor]\n",
    "            thisSet = set(sampleInfo.loc[:,sampleInfo.loc[factorType] == factor].columns)\n",
    "            # print('thisSet')\n",
    "            # print(thisSet)\n",
    "            AOISuperSets[i].append(thisSet)\n",
    "    # print('\\n')\n",
    "    # print('AOISuperSets[0]')\n",
    "    # print(AOISuperSets[0][0])\n",
    "    # print(AOISuperSets[0][1])\n",
    "    # print('AOISuperSets[1]')\n",
    "    # print(AOISuperSets[1][0])\n",
    "    # print(AOISuperSets[1][1])\n",
    "    numeratorAOIs = set.intersection(*AOISuperSets[0])\n",
    "    # print('\\n')\n",
    "    # print('numeratorAOIs')\n",
    "    # print(numeratorAOIs)\n",
    "    denominatorAOIs = set.intersection(*AOISuperSets[1])     \n",
    "    # print('denominatorAOIs')\n",
    "    # print(denominatorAOIs)\n",
    "    # print('\\n\\n')\n",
    "    relevantAOIs = list(numeratorAOIs | denominatorAOIs)\n",
    "    relevantAOIs = [x.replace('.',' ') for x in relevantAOIs]\n",
    "    fields.remove('vs')\n",
    "    return(relevantAOIs, fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29880251-2995-4f43-aaf6-18a1b3c9c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "for file in filesMaster:   # Iterate through files\n",
    "    if not (file[-7:-4] == '_tr'):  # Ignore _tr files with more stringent expression thresholding\n",
    "        print(file)\n",
    "        fileName = file.split('/')[-1]\n",
    "        # print(fileName)\n",
    "        relevantAOIs, fileNameFields = get_relevant_AOIs(fileName)\n",
    "        \n",
    "        subGenes = volcanoPlot(dataPath, file, pVal=True, plot=False)\n",
    "        # print(subGenes)\n",
    "        if (len(subGenes) <= 1):\n",
    "            print('No subgenes were found, continuing with next comparison\\n\\n')\n",
    "            continue\n",
    "        tempDF = pd.read_csv(file)\n",
    "        tempDF.columns = [x.replace('.',' ') for x in tempDF.columns]\n",
    "        # heatMapData = QCData.loc[subGenes,relevantAOIs] # Use EdgeR Input data for heatmaps\n",
    "        heatMapData = tempDF.loc[subGenes,relevantAOIs] # Use EdgeR model output data for heatmaps\n",
    "        # print('heatMapData.shape')\n",
    "        # print('heatMapData.columns')\n",
    "        # print(heatMapData.columns)\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(len(relevantAOIs)*0.27+3.5, len(subGenes)*0.27+3),width_ratios=[4,len(relevantAOIs),1], height_ratios=[4,2,len(subGenes)])\n",
    "\n",
    "\n",
    "        # gs = axs[1, 2].get_gridspec()\n",
    "        # # remove the underlying Axes\n",
    "        # for ax in axs[0:1, -1]:\n",
    "        #     ax.remove()\n",
    "        # axbig = fig.add_subplot(gs[0:1, -1])\n",
    "        # axbig.annotate('Big Axes \\nGridSpec[1:, -1]', (0.1, 0.5),\n",
    "        #                xycoords='axes fraction', va='center')\n",
    "\n",
    "\n",
    "        \n",
    "        ## Generate sample dendrogram\n",
    "        model = dendroModel.fit(heatMapData.T)\n",
    "        labels = plot_dendrogram(model, \n",
    "                                 truncate_mode=None, \n",
    "                                 p=5, \n",
    "                                 ax=axes[0][1])\n",
    "        # plt.title(\"Hierarchical Clustering Dendrogram of AOIs\")\n",
    "        # plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "        # plt.show()\n",
    "        AOINamesDendro = [heatMapData.columns[int(x)] for x in labels]\n",
    "        # print(AOINamesDendro)\n",
    "        \n",
    "        ## Generate probe dendrogram\n",
    "        model = dendroModel.fit(heatMapData)\n",
    "        labels = plot_dendrogram(model, \n",
    "                                 truncate_mode=None, \n",
    "                                 p=5, \n",
    "                                 orientation = 'left',\n",
    "                                 ax=axes[2][0])\n",
    "        # plt.title(\"Hierarchical Clustering Dendrogram of probes\")\n",
    "        # plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "        probeNamesDendro = [heatMapData.index[int(x)] for x in labels][::-1]\n",
    "        # print('probeNamesDendro')\n",
    "        # print(probeNamesDendro)\n",
    "\n",
    "        axes[0][0].axis('off')\n",
    "        # axes[0][1].axis('off')\n",
    "        axes[1][0].axis('off')\n",
    "        # axes[1][1].axis('off')\n",
    "        axes[0][2].axis('off')\n",
    "        axes[1][2].axis('off')\n",
    "        \n",
    "        axes[0][1].tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False) \n",
    "        axes[1][1].tick_params(left = False, right = True, labelright = True, labelbottom = False, top = False, bottom = False) \n",
    "        axes[2][0].tick_params(left = False, right = False, labelleft = False, labelright = False, labelbottom = False, bottom = False) \n",
    "        # axes[2][1].tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False) \n",
    "        # axes[2][0].set_yticks()\n",
    "\n",
    "        vars=['Histo_Stage','Segment_Name']\n",
    "        tempVarLookup={'IA':0.1,'IIA':0.2,'IIB':0.33,'IV':0.4,'Segment1':0.65,'Segment2':0.85}\n",
    "        # axes[1][1].matshow(get_var_colours(AOINamesDendro), cmap = 'nipy_spectral', aspect='auto', vmin=0, vmax=1)\n",
    "        # axes[1][1].matshow(get_var_colours(AOINamesDendro, vars=['Broad_classification'],tempVarLookup={'Primary':0.15,'Secondary':0.85}), cmap = 'gist_rainbow', aspect='auto', vmin=0, vmax=1)\n",
    "        axes[1][1].matshow(get_var_colours(AOINamesDendro, vars=vars,tempVarLookup=tempVarLookup), \n",
    "                           cmap = 'gist_rainbow', \n",
    "                           aspect='auto', \n",
    "                           vmin=0, \n",
    "                           vmax=1)\n",
    "        axes[1][1].yaxis.tick_right()\n",
    "        axes[1][1].set_yticks(np.linspace(0, len(vars)-1, len(vars)), vars)\n",
    "        axes[1][1].set_xticks([])\n",
    "\n",
    "        \n",
    "        # print('fileNameFields')\n",
    "        # print(fileNameFields)\n",
    "        axes[0][2].matshow([[tempVarLookup[x]] for x in fileNameFields], \n",
    "                           cmap = 'gist_rainbow', \n",
    "                           aspect='auto', \n",
    "                           vmin=0, \n",
    "                           vmax=1)\n",
    "        \n",
    "        axes[2][1].matshow(np.log2(heatMapData.loc[probeNamesDendro,AOINamesDendro]), cmap = 'coolwarm', aspect='auto')\n",
    "        axes[2][1].xaxis.tick_bottom()\n",
    "        axes[2][1].yaxis.tick_right()\n",
    "        # axes[2][1].set_xticklabels(AOINamesDendro)\n",
    "        # axes[2][1].set_yticks(np.linspace(0, len(probeNamesDendro)-1, len(probeNamesDendro)), probeNamesDendro)\n",
    "        # axes[2][1].set_xticks(np.linspace(0, len(AOINamesDendro)-1, len(AOINamesDendro)), ['AOI_' + x[22:-9] for x in AOINamesDendro], rotation = 45, ha='right')\n",
    "        axes[2][1].set_xticks(np.linspace(0, len(AOINamesDendro)-1, len(AOINamesDendro)), ['AOI_' + x[22:] for x in AOINamesDendro], rotation = 45, ha='right')\n",
    "        # axes[2][1].set_yticklabels(probeNamesDendro)\n",
    "        # axes[2][1].set_yticks(probeNamesDendro)\n",
    "        axes[2][1].set_yticks(np.linspace(0, len(probeNamesDendro)-1, len(probeNamesDendro)), probeNamesDendro)\n",
    "\n",
    "        norm = Normalize(vmin=np.log2(heatMapData.values.max()), vmax=np.log2(heatMapData.values.max()), clip=False)\n",
    "        fig.colorbar(ScalarMappable(norm=norm, cmap='coolwarm'), cax=axes[2][2])\n",
    "        \n",
    "        fig.suptitle(fileName[:-4])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file[:-4] + '_Heatmap.svg')\n",
    "        plt.show()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d2e2a-874b-4a70-afe4-f522374c5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo : Add x ticks to sample plot\n",
    "# ToDo : Add legend for sample ID plot\n",
    "# ToDo : Add legend for heatmap\n",
    "# ToDo : automate extraction of factor names and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283d3e3-77e0-445a-a303-fda578e8f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapData.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ed6dd-11dd-495d-9f50-6a5defabd4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapData.values.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e451119-1a17-41bb-ac54-3fb45c0595ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## plot \n",
    "\n",
    "# model = AgglomerativeClustering(n_clusters=None, \n",
    "#                                 affinity='euclidean', \n",
    "#                                 memory=None, \n",
    "#                                 connectivity=None, \n",
    "#                                 compute_full_tree=True, \n",
    "#                                 linkage='ward', \n",
    "#                                 distance_threshold=0.1, \n",
    "#                                 compute_distances=True\n",
    "#                                )\n",
    "\n",
    "# model = model.fit(QCData.drop(labels=['Code.Class'], axis=1).T)\n",
    "\n",
    "# plt.title(\"Hierarchical Clustering Dendrogram of AOIs\")\n",
    "# labels = plot_dendrogram(model, truncate_mode=None, p=5)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.savefig('dendrogram.svg')\n",
    "# plt.show()\n",
    "\n",
    "# # print(labels)\n",
    "# AOINamesDendro = [QCData.drop(labels=['Code.Class'], axis=1).columns[int(x)] for x in labels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4c138-e9a7-43d3-88b2-a49155ce266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.fit(QCData.drop(labels=['Code.Class'], axis=1))\n",
    "\n",
    "# plt.title(\"Hierarchical Clustering Dendrogram of probes\")\n",
    "# labels = plot_dendrogram(model, truncate_mode=None, p=5)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.savefig('dendrogram.svg')\n",
    "# plt.show()\n",
    "\n",
    "# # print(labels)\n",
    "# probeNamesDendro = [QCData.index[int(x)] for x in labels]\n",
    "# print(probeNamesDendro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d43d4-4cde-4fe5-abeb-52810add0b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c022f-34af-4bfc-bdc3-8baf275f7cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e471b-3a86-4153-b6f4-2c303fa8cbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83743fa0-d398-45a4-b87e-895fd07515bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ee010-7e0e-468f-9f42-73d60188d69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataPath = '../../../Nanostring/projects/.../DSP_Protein_Data/'\n",
    "dataPath = configDict['rootDir']\n",
    "data = pd.read_csv(os.path.join(dataPath,'HK_Geo_Mean_Normalised.csv'), index_col = 0)\n",
    "probeFilter = pd.read_csv(os.path.join(dataPath,'Probe_Filter.csv'), index_col = 0)\n",
    "sampleInfo = pd.read_csv(os.path.join(dataPath,'Sample_Info.csv'), index_col = 0)\n",
    "\n",
    "# dataPath = '../../../Nanostring/projects/.../EdgeR/EdgeR_normData.tsv'\n",
    "dataPath = os.path.join(configDict['rootDir'], normPath, normFile)\n",
    "\n",
    "data = pd.read_csv(dataPath, index_col = 0)\n",
    "\n",
    "# dataPath = '../../../Nanostring/projects/.../DSP_Protein_Data/'\n",
    "dataPath = configDict['rootDir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46727c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7886714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(os.path.join(dataPath,'Annotation template file-1a_wells_02.xlsx'))\n",
    "\n",
    "print(wb.sheetnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d059dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb['Annotation template']\n",
    "\n",
    "segments = [[y.value for y in x] for x in ws[ws.calculate_dimension()]]\n",
    "df = pd.DataFrame(segments)\n",
    "\n",
    "\n",
    "rowLabels = df.iloc[1:,0]\n",
    "colLabels = df.iloc[0,1:]\n",
    "annotations = df.iloc[1:,1:]\n",
    "rowLabels += '_'\n",
    "rowLabels += df.iloc[1:,1]\n",
    "rowLabels += '_Full ROI'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad61d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bc35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15288fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations = pd.DataFrame(annotations.values, index=rowLabels, columns=colLabels)\n",
    "\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "# sampleAnnotations.set_index(0, drop=True, inplace=True)\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "# sampleAnnotations.set_index('Scan name', drop=True, inplace=True)\n",
    "# sampleAnnotations = sampleAnnotations.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations = sampleAnnotations.join(sampleInfo.T,lsuffix='Drop').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAnnotations.drop(labels=[x for x in sampleAnnotations.index if x.endswith('Drop')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd77cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleInfo = sampleAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fe771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461799ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(arr):\n",
    "         \n",
    "    '''\n",
    "    This function standardize an array, its substracts mean value, \n",
    "    and then divide the standard deviation.\n",
    "    \n",
    "    param 1: array \n",
    "    return: standardized array\n",
    "    '''    \n",
    "    rows, columns = arr.shape\n",
    "    \n",
    "    standardizedArray = np.zeros(shape=(rows, columns))\n",
    "    tempArray = np.zeros(rows)\n",
    "    \n",
    "    for column in range(columns):\n",
    "        \n",
    "        mean = np.mean(X[:,column])\n",
    "        std = np.std(X[:,column])\n",
    "        tempArray = np.empty(0)\n",
    "        \n",
    "        for element in X[:,column]:\n",
    "            \n",
    "            tempArray = np.append(tempArray, ((element - mean) / std))\n",
    " \n",
    "        standardizedArray[:,column] = tempArray\n",
    "    \n",
    "    return standardizedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "\n",
    "### I'm not sure that the transpose is what i want here. The data is the wrong shape and pc's seems to be being calculated for proteins instead of samples\n",
    "X = endogNorm.transpose().values\n",
    "# X = endogNorm.values\n",
    "### Try to get pc's for samples\n",
    "# X = endogNorm.values\n",
    "\n",
    "## ??? With transpose makes PCA for effect of variables on smaples, without makes PCA for effects of variables on protein expression levels\n",
    "###^^^ Maybe the other way round?\n",
    "\n",
    "\n",
    "\n",
    "X_cols = endogNorm.columns\n",
    "print(X_cols.shape)\n",
    "y = endogNorm.index\n",
    "print(y.shape)\n",
    "X = standardize_data(X)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df305d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the covariance matrix\n",
    "\n",
    "covariance_matrix = np.cov(X.T)\n",
    "# covariance_matrix = np.cov(X)\n",
    "\n",
    "\n",
    "\n",
    "print(covariance_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e99c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using np.linalg.eig function\n",
    "\n",
    "eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
    "print(\"Eigenvector: \\n\",eigen_vectors,\"\\n\")\n",
    "print(\"Eigenvalues: \\n\", eigen_values, \"\\n\")\n",
    "print(eigen_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dbfd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigenDF = pd.DataFrame(eigen_vectors, index=[endogNorm.index], columns=[endogNorm.index])\n",
    "# eigenDF = pd.DataFrame(eigen_vectors, index=[endogNorm.columns], columns=[endogNorm.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the explained variance on each of components\n",
    "\n",
    "\n",
    "variance_explained = []\n",
    "for i in eigen_values:\n",
    "     variance_explained.append((i/sum(eigen_values))*100)\n",
    "        \n",
    "print(variance_explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b83e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying components that explain at least 95%\n",
    "\n",
    "cumulative_variance_explained = np.cumsum(variance_explained)\n",
    "print(cumulative_variance_explained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d49f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_explained = [np.float64(x) for x in cumulative_variance_explained]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc40023",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_explained[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca42949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the eigenvalues and finding the \"elbow\" in the graphic\n",
    "\n",
    "\n",
    "sns.lineplot(x = [i for i in range(len(cumulative_variance_explained))], y=cumulative_variance_explained)\n",
    "# plt.xlabel(\"Number of components\")\n",
    "# plt.ylabel(\"Cumulative explained variance\")\n",
    "# plt.title(\"Explained variance vs Number of components\")\n",
    "\n",
    "\n",
    "\n",
    "# ToDo:\n",
    "# Add lines for 95% variance, and number of components describing at least 95% of variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using two first components (because those explain more than 95%)\n",
    "\n",
    "projection_matrix = (eigen_vectors.T[:][:50]).T\n",
    "print(projection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['g' if x.split('_')[-1] == 'Tumour' else 'r' for x in X_cols]\n",
    "colours = ['g' if x.split('_')[-1] == 'Tumour' else 'r' if x.split('_')[-1] == 'Immune' else 'purple' for x in X_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78105cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont think this gives relevant info. projection matrix needs to be combined with original data to see effects of components on patients\n",
    "\n",
    "plt.scatter([x[0] for x in projection_matrix], [x[1] for x in projection_matrix])#, c=colours)\n",
    "\n",
    "projection_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x[2] for x in projection_matrix], [x[1] for x in projection_matrix])#, c=colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87721766",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x[2] for x in projection_matrix], [x[3] for x in projection_matrix])#, c=colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the product of original standardized X and the eigenvectors \n",
    "\n",
    "\n",
    "X_pca = X.dot(projection_matrix)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e99136",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383154c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fe4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagDF = pd.DataFrame( data=[x.split(',') for x in sampleInfo.loc['Segment tags']], index=sampleInfo.columns, columns=['Obese','Arth','Patellar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05005bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleInfo = pd.concat([sampleInfo,tagDF.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c206dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5523ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inforSortedIndex = sampleInfo.sort_values(by=['Obese','arthritis','TMA_Core'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b7c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe99ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f507eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add umap / tSNE analysis here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9bd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01af0aba-f48f-40ea-8090-1eb3c4e80665",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
